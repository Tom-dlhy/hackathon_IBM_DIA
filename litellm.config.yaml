# litellm.config.yaml
model_list:
  # ——— Llama (watsonx) ———
  - model_name: llama-3.3-70b-instruct
    litellm_params:
      model: watsonx/meta-llama/llama-3-3-70b-instruct
      api_key: os.environ/WATSONX_APIKEY
      # project_id: os.environ/WATSONX_PROJECT_ID
      # temperature: 0.7
      # max_tokens: 4096

  - model_name: granite-embed-278m-multi
    litellm_params:
      model: watsonx/ibm/granite-embedding-278m-multilingual
      api_key: os.environ/WATSONX_APIKEY
      # project_id: os.environ/WATSONX_PROJECT_ID
      mode: embedding

  - model_name: multilingual-e5-large
    litellm_params:
      model: watsonx/intfloat/multilingual-e5-large
      api_key: os.environ/WATSONX_APIKEY
      mode: embedding

general_settings:
  telemetry: false
  debug: false
